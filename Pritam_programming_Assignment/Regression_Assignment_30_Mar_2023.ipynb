{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "166fcf0c",
   "metadata": {},
   "source": [
    "### Q1. What is Elastic Net Regression and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bf0e14",
   "metadata": {},
   "source": [
    "Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf58c2db",
   "metadata": {},
   "source": [
    "1.Elastic net regression is a linear regression technique that uses a penalty term to shrink the coefficients of the predictors.\n",
    "\n",
    "2.Which is combination of lasso and ridge regression.\n",
    "\n",
    "3.It is the use for to reduce overfitting and to feature selection.\n",
    "\n",
    "4.It is formula , \n",
    "\n",
    "\n",
    "#### Elastic Net Regression = (1 / n) * (yact - ypred)^2 + lambda * (slope)^2 + lambda * slope\n",
    "\n",
    "\n",
    "yact = Actual output data points\n",
    "\n",
    "ypred = prediction output data points\n",
    "\n",
    "lambda = Hyperparameter \n",
    "\n",
    "slope^2 = square of slope\n",
    "\n",
    "slope = Actual value of slope\n",
    "\n",
    "\n",
    "\n",
    "#### It is differ from other regression technique like lasso and ridge\n",
    "\n",
    "#### Lasso Regression : \n",
    "\n",
    "    It is used for feature selection .\n",
    "  \n",
    "    It is also called L1 Regularization\n",
    "  \n",
    " \n",
    "#### Ridge Regression:\n",
    "\n",
    "    It is used for overfitting.\n",
    "    \n",
    "    It is also called L2 Regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28e87e0",
   "metadata": {},
   "source": [
    "### Q2. How do you choose the optimal values of the regularization parameters for Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c852fd",
   "metadata": {},
   "source": [
    "Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e9dbf2",
   "metadata": {},
   "source": [
    "1.Choosing the optimal values of regularization parameters for \n",
    "\n",
    "  Elastic Net Regression involves a process called hyperparameter tuning.\n",
    "\n",
    "  This process involves selecting a range of values for the regularization parameters, training the model on a training \n",
    "\n",
    "  set with different combinations of those values, and evaluating the model's performance on a validation set. \n",
    "\n",
    "2.The best combination of hyperparameters is the one that produces the highest performance on the validation set.\n",
    "\n",
    "3.Here are the steps to choose the optimal values of regularization parameters for Elastic Net Regression:\n",
    "\n",
    "   Divide your data into three sets: a training set, a validation set, and a test set. \n",
    "    \n",
    "   The training set will be used to train the model, the validation set to tune the hyperparameters, \n",
    "\n",
    "   and the test set to evaluate the final performance of the model.\n",
    "\n",
    "4.Define a range of values for the two regularization parameters in Elastic Net Regression: alpha and l1_ratio. \n",
    "    \n",
    "   Alpha controls the overall strength of regularization, while l1_ratio controls the balance between L1 and L2 regularization.\n",
    "\n",
    "5.Create a grid of possible combinations of alpha and l1_ratio values. \n",
    "\n",
    "6.This can be done using the GridSearchCV function in Scikit-learn.\n",
    "\n",
    "7.For each combination of hyperparameters in the grid, train an Elastic Net Regression model on the training set \n",
    "\n",
    "  and evaluate its performance on the validation set.\n",
    "\n",
    "8.Choose the combination of hyperparameters that produces the best performance on the validation set.\n",
    "\n",
    "9.Train a new Elastic Net Regression model with the chosen hyperparameters on the combined training and validation sets.\n",
    "\n",
    "10.Evaluate the performance of the final model on the test set to get an estimate of its generalization performance.\n",
    "\n",
    "11.Repeat steps 4-7 until the desired level of performance is achieved.\n",
    "\n",
    "12.Its important to note that hyperparameter tuning can be a computationally expensive process, especially \n",
    "\n",
    "   if the data set is large or the range of hyperparameters is wide. Therefore, it's important to use techniques like \n",
    "    \n",
    "   cross-validation to make the most out of the available data and compute resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01a0cba",
   "metadata": {},
   "source": [
    "### Q3. What are the advantages and disadvantages of Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52aaa6f",
   "metadata": {},
   "source": [
    "Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be86b75c",
   "metadata": {},
   "source": [
    "#### Advantages :\n",
    "\n",
    "1.One of the benefits of elastic net is that it can handle multicollinearity, \n",
    "\n",
    "which is when some predictors are highly correlated with each other. Lasso can suffer from instability and inconsistency \n",
    "\n",
    "when there is multicollinearity, as it may arbitrarily select one predictor over another. \n",
    "\n",
    "Ridge can handle multicollinearity better, but it may keep too many predictors that are not relevant. \n",
    "\n",
    "Elastic net can overcome these problems by selecting a subset of predictors that are correlated, but not redundant.\n",
    "\n",
    "2.Another benefit of elastic net is that it can reduce overfitting, which is when the model fits the training data too well,\n",
    "\n",
    "but performs poorly on new or unseen data. Lasso and ridge can also reduce overfitting by adding regularization, \n",
    "\n",
    "but elastic net can do it more effectively by combining the benefits of both methods. \n",
    "\n",
    "Elastic net can balance the bias-variance trade-off by finding a middle ground between underfitting and overfitting.\n",
    "\n",
    "3.A third benefit of elastic net is that it can perform feature selection, which is when the model identifies the \n",
    "\n",
    "most important predictors for the outcome. Lasso can also perform feature selection by setting some coefficients to zero, \n",
    "\n",
    "but it may miss some relevant predictors if there are too many of them. Ridge cannot perform feature selection, as it keeps\n",
    "\n",
    "all the predictors, but shrinks them. Elastic net can perform feature selection by setting some coefficients to zero, \n",
    "\n",
    "while keeping others that are significant.\n",
    "\n",
    "\n",
    "\n",
    "#### Disadvantages :\n",
    "\n",
    "1.One of the pitfalls and challenges of elastic net is that it requires tuning two hyperparameters: alpha and lambda. \n",
    "\n",
    "Hyperparameters are parameters that are not learned by the model, but need to be specified by the user. Tuning \n",
    "\n",
    "hyperparameters means finding the optimal values that minimize the error or maximize the performance of the model. Tuning\n",
    "\n",
    "hyperparameters can be time-consuming and computationally expensive, as it requires testing different combinations of \n",
    "\n",
    "values and evaluating their results.\n",
    "\n",
    "\n",
    "\n",
    "2.Another pitfall and challenge of elastic net is that it may not work well for some types of data or problems. For \n",
    "\n",
    "example, elastic net may not be suitable for high-dimensional data, where the number of predictors is much larger than the \n",
    "\n",
    "number of observations. In this case, elastic net may not be able to select the relevant features or reduce the \n",
    "\n",
    "dimensionality effectively. Elastic net may also not be suitable for non-linear problems, where the relationship between \n",
    "\n",
    "the predictors and the outcome is not linear. In this case, elastic net may not be able to capture the complexity or the \n",
    "\n",
    "interactions of the data.\n",
    "\n",
    "\n",
    "\n",
    "3.A third pitfall and challenge of elastic net is that it may not be interpretable or explainable. Interpretability and \n",
    "\n",
    "explainability are the ability to understand how the model works and why it makes certain predictions. Lasso and ridge are \n",
    "\n",
    "relatively simple and intuitive, as they have a clear relationship between the coefficients and the predictors. Elastic net\n",
    "\n",
    "is more complex and ambiguous, as it involves a combination of two penalties and two hyperparameters. Elastic net may not \n",
    "\n",
    "provide a clear or meaningful explanation of the model or its results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6b51b8",
   "metadata": {},
   "source": [
    "### Q5. How do you interpret the coefficients in Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c361abe5",
   "metadata": {},
   "source": [
    "Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c49349",
   "metadata": {},
   "source": [
    "Elastic Net Regression is a linear regression model that combines L1 and L2 regularization to overcome some of the limitations of each method. The model introduces two hyperparameters, alpha and l1_ratio, that control the balance between the two types of regularization.\n",
    "\n",
    "In Elastic Net Regression, the coefficients represent the relationship between each independent variable and the dependent variable. The interpretation of the coefficients depends on the value of the regularization hyperparameters and the scaling of the variables.\n",
    "\n",
    "When the L1 regularization parameter (alpha) is large, Elastic Net Regression tends to set some of the coefficients to zero, effectively performing variable selection. The remaining non-zero coefficients represent the variables that are most important in predicting the dependent variable. The magnitude of the non-zero coefficients reflects the strength and direction of the relationship between the corresponding independent variable and the dependent variable.\n",
    "\n",
    "When the L2 regularization parameter (alpha) is large, Elastic Net Regression tends to shrink the coefficients towards zero, effectively reducing the impact of each independent variable on the dependent variable. The magnitude of the non-zero coefficients is still informative, but it is important to keep in mind that the model has reduced the impact of each variable.\n",
    "\n",
    "The l1_ratio hyperparameter controls the balance between L1 and L2 regularization. When l1_ratio is close to 0, Elastic Net Regression behaves like Ridge Regression, and when l1_ratio is close to 1, it behaves like Lasso Regression. When l1_ratio is between 0 and 1, Elastic Net Regression strikes a balance between variable selection and coefficient shrinkage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11e67fe",
   "metadata": {},
   "source": [
    "### Q6. How do you handle missing values when using Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859e8932",
   "metadata": {},
   "source": [
    "Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eaee1d",
   "metadata": {},
   "source": [
    "Simple approaches include taking the average of the column and use that value, or if there is a heavy skew the median might be better. A better approach, you can perform regression or nearest neighbor imputation on the column to predict the missing values. Then continue on with your analysis/model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf73c794",
   "metadata": {},
   "source": [
    "### Q7. How do you use Elastic Net Regression for feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdf2843",
   "metadata": {},
   "source": [
    "Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93405b8",
   "metadata": {},
   "source": [
    "Elastic Net Regression is extension of linear regression.\n",
    "\n",
    "Elastic Net Regression is combination of ridge and lasso regression.\n",
    "\n",
    "Ridge regression is used for to avoid overfitting.\n",
    "\n",
    "Lasso regression is used for to feature selection.\n",
    "\n",
    "Lasso regression is work like which variable is not correleate to output variable.\n",
    "\n",
    "That feature should be zero and it removed and selects those remaining features.\n",
    "\n",
    "so , we can use Elastic Net Regression for feature selection.\n",
    "\n",
    "we can use correleation for feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0503dad1",
   "metadata": {},
   "source": [
    "### Q8. How do you pickle and unpickle a trained Elastic Net Regression model in Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5459d6e",
   "metadata": {},
   "source": [
    "Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7519ae",
   "metadata": {},
   "source": [
    "First we need to import pickle module.\n",
    "\n",
    "then pickle module has function called dump so it convert python code into another format. so make pickle file.\n",
    "\n",
    "if that file we want to open or use that code then just import pickle and pickle has another function called load.\n",
    "\n",
    "load is used to convert object into python code / format.\n",
    "\n",
    "eg :\n",
    "    \n",
    "    \n",
    "    import pickle\n",
    "    \n",
    "    regression = pickle.dump(regressor , open('regression.pkl' , wb))\n",
    "    \n",
    "    model_regression = pickle.load(open('regression.pkl' ,'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e88ec23",
   "metadata": {},
   "source": [
    "### Q9. What is the purpose of pickling a model in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8737d42",
   "metadata": {},
   "source": [
    "Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fcef9e",
   "metadata": {},
   "source": [
    "Pickle is a useful Python tool that allows you to save your ML models, to minimise lengthy re-training and allow you to share, commit, and re-load pre-trained machine learning models. Most data scientists working in ML will use Pickle or Joblib to save their ML model for future use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
